{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparing the dataset for hippocampus segmentation\n",
    "\n",
    "In this notebook you will use the skills and methods that we have talked about during our EDA Lesson to prepare the hippocampus dataset using Python. Follow the Notebook, writing snippets of code where directed so using Task comments, similar to the one below, which expects you to put the proper imports in place. Write your code directly in the cell with TASK comment. Feel free to add cells as you see fit, but please make sure that code that performs that tasked activity sits in the same cell as the Task comment.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting glob\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  ERROR: Could not find a version that satisfies the requirement glob (from versions: none)\n",
      "ERROR: No matching distribution found for glob\n"
     ]
    }
   ],
   "source": [
    "#!pip install nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Import the following libraries that we will use: nibabel, matplotlib, numpy\n",
    "import nibabel\n",
    "import matplotlib as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will help your understanding of the data a lot if you were able to use a tool that allows you to view NIFTI volumes, like [3D Slicer](https://www.slicer.org/). I will refer to Slicer throughout this Notebook and will be pasting some images showing what your output might look like."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading NIFTI images using NiBabel\n",
    "\n",
    "NiBabel is a python library for working with neuro-imaging formats (including NIFTI) that we have used in some of the exercises throughout the course. Our volumes and labels are in NIFTI format, so we will use nibabel to load and inspect them.\n",
    "\n",
    "NiBabel documentation could be found here: https://nipy.org/nibabel/\n",
    "\n",
    "Our dataset sits in two directories - *images* and *labels*. Each image is represented by a single file (we are fortunate to have our data converted to NIFTI) and has a corresponding label file which is named the same as the image file.\n",
    "\n",
    "Note that our dataset is \"dirty\". There are a few images and labels that are not quite right. They should be quite obvious to notice, though. The dataset contains an equal amount of \"correct\" volumes and corresponding labels, and you don't need to alter values of any samples in order to get the clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Your data sits in directory /data/TrainingSet.\n",
    "# Load an image and a segmentation mask into variables called image and label\n",
    "image = nibabel.nifti1.load(\"C:/Users/Daniel/Desktop/Hippocampal Volume Quantification in Alzheimer's Progression/Section 1/out/TrainingSet/images/hippocampus_001.nii.gz\")\n",
    "label = 'hippocampus_001.nii'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35, 51, 35)\n"
     ]
    }
   ],
   "source": [
    "# Nibabel can present your image data as a Numpy array by calling the method get_fdata()\n",
    "# The array will contain a multi-dimensional Numpy array with numerical values representing voxel intensities. \n",
    "# In our case, images and labels are 3-dimensional, so get_fdata will return a 3-dimensional array. You can verify this\n",
    "# by accessing the .shape attribute. What are the dimensions of the input arrays?\n",
    "\n",
    "nifti_array = image.get_fdata()\n",
    "nifti_array.shape\n",
    "\n",
    "# TASK: using matplotlib, visualize a few slices from the dataset, along with their labels. \n",
    "# You can adjust plot sizes like so if you find them too small:\n",
    "# plt.rcParams[\"figure.figsize\"] = (10,10)\n",
    "plt.rcParams[\"figure.figsize\"] = (10,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load volume into 3D Slicer to validate that your visualization is correct and get a feel for the shape of structures.Try to get a visualization like the one below (hint: while Slicer documentation is not particularly great, there are plenty of YouTube videos available! Just look it up on YouTube if you are not sure how to do something)\n",
    "\n",
    "![3D slicer](img/Slicer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hippocampus_001.nii.gz - memory size of image: 49874, shape: (35, 51, 35)\n",
      "hippocampus_007.nii.gz - memory size of image: 83038, shape: (34, 47, 40)\n",
      "hippocampus_010.nii.gz : Unreadable image file. Memory size = 83038\n",
      "hippocampus_015.nii.gz - memory size of image: 73716, shape: (42, 51, 28)\n",
      "hippocampus_019.nii.gz - memory size of image: 87302, shape: (36, 47, 41)\n",
      "hippocampus_020.nii.gz - memory size of image: 89703, shape: (36, 46, 43)\n",
      "hippocampus_025.nii.gz - memory size of image: 72996, shape: (35, 48, 35)\n",
      "hippocampus_026.nii.gz - memory size of image: 80500, shape: (36, 50, 36)\n",
      "hippocampus_049.nii.gz - memory size of image: 79879, shape: (35, 51, 36)\n",
      "hippocampus_050.nii.gz - memory size of image: 88013, shape: (38, 49, 38)\n",
      "hippocampus_053.nii.gz - memory size of image: 88702, shape: (37, 51, 35)\n",
      "hippocampus_064.nii.gz - memory size of image: 77096, shape: (35, 53, 35)\n",
      "hippocampus_065.nii.gz - memory size of image: 60545, shape: (39, 52, 37)\n",
      "hippocampus_068.nii.gz - memory size of image: 78852, shape: (36, 40, 43)\n",
      "hippocampus_093.nii.gz - memory size of image: 84725, shape: (34, 53, 37)\n",
      "hippocampus_094.nii.gz - memory size of image: 91190, shape: (38, 50, 38)\n",
      "hippocampus_098.nii.gz - memory size of image: 71912, shape: (37, 48, 34)\n",
      "hippocampus_099.nii.gz - memory size of image: 57286, shape: (33, 52, 27)\n",
      "hippocampus_109.nii.gz - memory size of image: 51360, shape: (36, 49, 36)\n",
      "hippocampus_114.nii.gz - memory size of image: 61301, shape: (38, 50, 39)\n",
      "hippocampus_123.nii.gz - memory size of image: 54403, shape: (32, 53, 38)\n",
      "hippocampus_125.nii.gz - memory size of image: 58805, shape: (43, 42, 39)\n",
      "hippocampus_126.nii.gz - memory size of image: 61241, shape: (39, 44, 43)\n",
      "hippocampus_127.nii.gz - memory size of image: 53598, shape: (38, 55, 31)\n",
      "hippocampus_133.nii.gz - memory size of image: 53095, shape: (39, 41, 42)\n",
      "hippocampus_136.nii.gz - memory size of image: 83180, shape: (34, 49, 41)\n",
      "hippocampus_150.nii.gz - memory size of image: 50080, shape: (37, 49, 34)\n",
      "hippocampus_152.nii.gz - memory size of image: 58188, shape: (36, 53, 37)\n",
      "hippocampus_161.nii.gz - memory size of image: 51736, shape: (35, 51, 36)\n",
      "hippocampus_163.nii.gz - memory size of image: 60077, shape: (36, 47, 44)\n",
      "hippocampus_164.nii.gz - memory size of image: 74082, shape: (41, 48, 47)\n",
      "hippocampus_165.nii.gz - memory size of image: 39560, shape: (34, 49, 29)\n",
      "hippocampus_166.nii.gz - memory size of image: 44447, shape: (36, 49, 31)\n",
      "hippocampus_170.nii.gz - memory size of image: 79899, shape: (34, 48, 40)\n",
      "hippocampus_171.nii.gz - memory size of image: 43104, shape: (35, 56, 28)\n",
      "hippocampus_176.nii.gz - memory size of image: 79455, shape: (35, 50, 36)\n",
      "hippocampus_177.nii.gz - memory size of image: 45334, shape: (33, 44, 40)\n",
      "hippocampus_189.nii.gz - memory size of image: 69811, shape: (35, 53, 30)\n",
      "hippocampus_197.nii.gz - memory size of image: 49439, shape: (38, 51, 31)\n",
      "hippocampus_203.nii.gz - memory size of image: 80261, shape: (34, 49, 38)\n",
      "hippocampus_207.nii.gz - memory size of image: 74781, shape: (35, 53, 33)\n",
      "hippocampus_228.nii.gz - memory size of image: 77195, shape: (37, 48, 36)\n",
      "hippocampus_229.nii.gz - memory size of image: 74467, shape: (33, 50, 35)\n",
      "hippocampus_232.nii.gz - memory size of image: 82746, shape: (36, 44, 43)\n",
      "hippocampus_233.nii.gz - memory size of image: 77141, shape: (33, 51, 37)\n",
      "hippocampus_235.nii.gz - memory size of image: 88850, shape: (37, 58, 35)\n",
      "hippocampus_244.nii.gz - memory size of image: 75832, shape: (38, 53, 30)\n",
      "hippocampus_245.nii.gz - memory size of image: 85635, shape: (35, 48, 42)\n",
      "hippocampus_249.nii.gz - memory size of image: 73022, shape: (32, 52, 34)\n",
      "hippocampus_250.nii.gz - memory size of image: 82804, shape: (35, 51, 36)\n",
      "hippocampus_251.nii.gz - memory size of image: 49495, shape: (36, 58, 28)\n",
      "hippocampus_252.nii.gz - memory size of image: 44660, shape: (37, 55, 26)\n",
      "hippocampus_269.nii.gz - memory size of image: 79868, shape: (35, 49, 37)\n",
      "hippocampus_274.nii.gz - memory size of image: 70246, shape: (35, 40, 40)\n",
      "hippocampus_277.nii.gz - memory size of image: 69916, shape: (33, 59, 29)\n",
      "hippocampus_280.nii.gz - memory size of image: 69702, shape: (37, 47, 32)\n",
      "hippocampus_286.nii.gz - memory size of image: 59377, shape: (37, 45, 46)\n",
      "hippocampus_289.nii.gz - memory size of image: 73932, shape: (35, 49, 36)\n",
      "hippocampus_295.nii.gz - memory size of image: 78712, shape: (35, 53, 36)\n",
      "hippocampus_299.nii.gz - memory size of image: 73671, shape: (32, 54, 34)\n",
      "hippocampus_300.nii.gz - memory size of image: 79319, shape: (34, 53, 35)\n",
      "hippocampus_301.nii.gz - memory size of image: 70441, shape: (31, 50, 36)\n",
      "hippocampus_302.nii.gz - memory size of image: 79119, shape: (35, 46, 39)\n",
      "hippocampus_304.nii.gz - memory size of image: 79147, shape: (36, 48, 38)\n",
      "hippocampus_309.nii.gz - memory size of image: 83902, shape: (34, 52, 38)\n",
      "hippocampus_310.nii.gz - memory size of image: 86751, shape: (35, 52, 38)\n",
      "hippocampus_316.nii.gz - memory size of image: 75921, shape: (37, 51, 33)\n",
      "hippocampus_317.nii.gz - memory size of image: 70337, shape: (33, 51, 34)\n",
      "hippocampus_318.nii.gz - memory size of image: 77634, shape: (37, 51, 33)\n",
      "hippocampus_328.nii.gz - memory size of image: 70756, shape: (38, 54, 30)\n",
      "hippocampus_332.nii.gz - memory size of image: 72921, shape: (35, 52, 33)\n",
      "hippocampus_333.nii.gz - memory size of image: 77677, shape: (33, 46, 38)\n",
      "hippocampus_336.nii.gz - memory size of image: 83984, shape: (34, 47, 43)\n",
      "hippocampus_340.nii.gz - memory size of image: 71481, shape: (35, 46, 38)\n",
      "hippocampus_341.nii.gz - memory size of image: 74559, shape: (34, 48, 35)\n",
      "hippocampus_353.nii.gz - memory size of image: 61813, shape: (32, 51, 31)\n",
      "hippocampus_360.nii.gz - memory size of image: 76439, shape: (34, 49, 37)\n",
      "hippocampus_366.nii.gz - memory size of image: 74051, shape: (37, 47, 34)\n",
      "hippocampus_367.nii.gz - memory size of image: 92968, shape: (36, 57, 37)\n",
      "hippocampus_378.nii.gz - memory size of image: 75069, shape: (35, 52, 34)\n",
      "hippocampus_380.nii.gz - memory size of image: 88716, shape: (35, 46, 42)\n",
      "hippocampus_385.nii.gz - memory size of image: 85740, shape: (35, 48, 40)\n",
      "hippocampus_387.nii.gz - memory size of image: 66075, shape: (33, 51, 32)\n",
      "hippocampus_390.nii.gz - memory size of image: 85654, shape: (38, 51, 33)\n",
      "hippocampus_393.nii.gz - memory size of image: 68560, shape: (36, 51, 31)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "error_images = []\n",
    "image_count = 0\n",
    "label_count = 0\n",
    " \n",
    "for x in os.listdir(\"C:/Users/Daniel/Desktop/Hippocampal Volume Quantification in Alzheimer's Progression/Section 1/out/TrainingSet/images\"):\n",
    "    try:\n",
    "        if x.endswith(\".nii.gz\"):\n",
    "            image = nibabel.nifti1.load(\"C:/Users/Daniel/Desktop/Hippocampal Volume Quantification in Alzheimer's Progression/Section 1/out/TrainingSet/images/{}\".format(x))\n",
    "            nifti_array = image.get_fdata()\n",
    "            file_size = os.path.getsize(\"C:/Users/Daniel/Desktop/Hippocampal Volume Quantification in Alzheimer's Progression/Section 1/out/TrainingSet/images/{}\".format(x))\n",
    "            print(\"{} - memory size of image: {}, shape: {}\".format(x, file_size, nifti_array.shape))\n",
    "            image_count += 1\n",
    "    except:\n",
    "        print(\"{} : Unreadable image file. Memory size = {}\".format(x, file_size))\n",
    "        error_images.append(x)\n",
    "        image_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation: \n",
    "There is an error in image \"hippocampus_010.nii.gz.\" This image should be dropped from the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85\n"
     ]
    }
   ],
   "source": [
    "print(image_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stand out suggestion: use one of the simple Volume Rendering algorithms that we've\n",
    "# implemented in one of our earlier lessons to visualize some of these volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Looking at single image data\n",
    "In this section we will look closer at the NIFTI representation of our volumes. In order to measure the physical volume of hippocampi, we need to understand the relationship between the sizes of our voxels and the physical world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'nibabel.nifti1.Nifti1Header'> object, endian='<'\n",
      "sizeof_hdr      : 348\n",
      "data_type       : b''\n",
      "db_name         : b''\n",
      "extents         : 0\n",
      "session_error   : 0\n",
      "regular         : b'r'\n",
      "dim_info        : 0\n",
      "dim             : [ 3 36 51 31  1  1  1  1]\n",
      "intent_p1       : 0.0\n",
      "intent_p2       : 0.0\n",
      "intent_p3       : 0.0\n",
      "intent_code     : none\n",
      "datatype        : float32\n",
      "bitpix          : 32\n",
      "slice_start     : 0\n",
      "pixdim          : [1. 1. 1. 1. 1. 0. 0. 0.]\n",
      "vox_offset      : 0.0\n",
      "scl_slope       : nan\n",
      "scl_inter       : nan\n",
      "slice_end       : 0\n",
      "slice_code      : unknown\n",
      "xyzt_units      : 10\n",
      "cal_max         : 0.0\n",
      "cal_min         : 0.0\n",
      "slice_duration  : 0.0\n",
      "toffset         : 0.0\n",
      "glmax           : 0\n",
      "glmin           : 0\n",
      "descrip         : b'5.0.10'\n",
      "aux_file        : b'none'\n",
      "qform_code      : scanner\n",
      "sform_code      : scanner\n",
      "quatern_b       : 0.0\n",
      "quatern_c       : 0.0\n",
      "quatern_d       : 0.0\n",
      "qoffset_x       : 1.0\n",
      "qoffset_y       : 1.0\n",
      "qoffset_z       : 1.0\n",
      "srow_x          : [1. 0. 0. 1.]\n",
      "srow_y          : [0. 1. 0. 1.]\n",
      "srow_z          : [0. 0. 1. 1.]\n",
      "intent_name     : b''\n",
      "magic           : b'n+1'\n"
     ]
    }
   ],
   "source": [
    "# Nibabel supports many imaging formats, NIFTI being just one of them. I told you that our images \n",
    "# are in NIFTI, but you should confirm if this is indeed the format that we are dealing with\n",
    "# TASK: using .header_class attribute - what is the format of our images?\n",
    "header = image.header\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further down we will be inspecting .header attribute that provides access to NIFTI metadata. You can use this resource as a reference for various fields: https://brainder.org/2012/09/23/the-nifti-file-format/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 32 bits per pixel.\n"
     ]
    }
   ],
   "source": [
    "# TASK: How many bits per pixel are used?\n",
    "print(\"There are {} bits per pixel.\".format(header['bitpix']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The units of measurement are in 'mm'.\n"
     ]
    }
   ],
   "source": [
    "# TASK: What are the units of measurement?\n",
    "print(\"The units of measurement are in '{}'.\".format(header.get_xyzt_units()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1., 0., 0., 0.], dtype=float32)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TASK: Do we have a regular grid? What are grid spacings?\n",
    "header['pixdim']          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimensions for the image: [ 3 36 51 31  1  1  1  1]\n",
      "The second value in the array is the axial slice: 36\n",
      "The third value in the array is the sagittal slice: 51\n",
      "The fourth value in the array is the coronal slice: 31\n"
     ]
    }
   ],
   "source": [
    "# TASK: What dimensions represent axial, sagittal, and coronal slices? How do you know?\n",
    "print(\"Dimensions for the image: {}\".format(header['dim']))\n",
    "print(\"The second value in the array is the axial slice: {}\".format(header['dim'][1]))\n",
    "print(\"The third value in the array is the sagittal slice: {}\".format(header['dim'][2]))\n",
    "print(\"The fourth value in the array is the coronal slice: {}\".format(header['dim'][3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# By now you should have enough information to decide what are dimensions of a single voxel\n",
    "# TASK: Compute the volume (in mmÂ³) of a hippocampus using one of the labels you've loaded. \n",
    "# You should get a number between ~2200 and ~4500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "series = np.array([[(os.path.join(dp, f), pydicom.dcmread(os.path.join(dp, f), stop_before_pi))]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting some charts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Plot a histogram of all volumes that we have in our dataset and see how \n",
    "# our dataset measures against a slice of a normal population represented by the chart below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"img/nomogram_fem_right.svg\" width=400 align=left>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do you see any outliers? Why do you think it's so (might be not immediately obvious, but it's always a good idea to inspect) outliers closer. If you haven't found the images that do not belong, the histogram may help you."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the real world we would have precise information about the ages and conditions of our patients, and understanding how our dataset measures against population norm would be the integral part of clinical validation that we talked about in last lesson. Unfortunately, we do not have this information about this dataset, so we can only guess why it measures the way it is. If you would like to explore further, you can use the [calculator from HippoFit project](http://www.smanohar.com/biobank/calculator.html) to see how our dataset compares against different population slices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Did you notice anything odd about the label files? We hope you did! The mask seems to have two classes, labeled with values `1` and `2` respectively. If you visualized sagittal or axial views, you might have gotten a good guess of what those are. Class 1 is the anterior segment of the hippocampus and class 2 is the posterior one. \n",
    "\n",
    "For the purpose of volume calculation we do not care about the distinction, however we will still train our network to differentiate between these two classes and the background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TASK: Copy the clean dataset to the output folder inside section1/out. You will use it in the next Section\n",
    "!cp -r /data/TrainingSet /home/workspace/out/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "Congratulations! You have finished Section 1. \n",
    "\n",
    "In this section you have inspected a dataset of MRI scans and related segmentations, represented as NIFTI files. We have visualized some slices, and understood the layout of the data. We have inspected file headers to understand what how the image dimensions relate to the physical world and we have understood how to measure our volume. We have then inspected dataset for outliers, and have created a clean set that is ready for consumption by our ML algorithm. \n",
    "\n",
    "In the next section you will create training and testing pipelines for a UNet-based machine learning model, run and monitor the execution, and will produce test metrics. This will arm you with all you need to use the model in the clinical context and reason about its performance!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
